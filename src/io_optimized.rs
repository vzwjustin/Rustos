//! # I/O Optimization and Scheduling System
//!
//! This module provides an optimized I/O subsystem with request scheduling,
//! prioritization, and batching for improved performance.

use alloc::collections::VecDeque;
use alloc::vec::Vec;
use spin::Mutex;
use lazy_static::lazy_static;

/// I/O request priority levels
#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]
pub enum IoPriority {
    /// Critical real-time I/O
    Realtime,
    /// High priority I/O
    High,
    /// Normal priority I/O (default)
    Normal,
    /// Low priority background I/O
    Low,
    /// Best effort idle I/O
    Idle,
}

/// Type of I/O request
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum IoRequestType {
    /// Read operation
    Read,
    /// Write operation
    Write,
    /// Sync/flush operation
    Sync,
}

/// I/O completion status
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum IoCompletionStatus {
    /// Request is pending
    Pending,
    /// Request completed successfully
    Success,
    /// Request failed
    Error,
}

/// I/O request structure
#[derive(Debug, Clone)]
pub struct IoRequest {
    /// Unique request ID
    pub request_id: u64,
    /// Request ID (alias)
    pub id: u64,
    /// Type of I/O operation
    pub request_type: IoRequestType,
    /// Priority level
    pub priority: IoPriority,
    /// Target device/file descriptor
    pub target: u32,
    /// Data buffer offset
    pub offset: u64,
    /// Data buffer
    pub buffer: Option<u64>,
    /// Buffer size
    pub size: usize,
    /// Device ID
    pub device_id: u32,
    /// Waker for async operations
    pub waker: Option<u64>,
    /// Completion status
    pub completion_status: IoCompletionStatus,
}

/// I/O scheduler for optimizing disk and device access
pub struct IoScheduler {
    /// Queue of pending requests
    request_queue: Mutex<VecDeque<IoRequest>>,
    /// Next request ID
    next_request_id: Mutex<u64>,
    /// Statistics
    total_requests: Mutex<u64>,
    completed_requests: Mutex<u64>,
}

impl IoScheduler {
    /// Create a new I/O scheduler
    pub const fn new() -> Self {
        Self {
            request_queue: Mutex::new(VecDeque::new()),
            next_request_id: Mutex::new(1),
            total_requests: Mutex::new(0),
            completed_requests: Mutex::new(0),
        }
    }

    /// Submit an I/O request
    pub fn submit_request(&self, mut request: IoRequest) -> u64 {
        let mut next_id = self.next_request_id.lock();
        request.request_id = *next_id;
        *next_id += 1;
        drop(next_id);

        let request_id = request.request_id; // Save before moving

        let mut queue = self.request_queue.lock();
        queue.push_back(request);
        drop(queue);

        let mut total = self.total_requests.lock();
        *total += 1;

        request_id
    }

    /// Process pending I/O requests
    pub fn process_requests(&self) -> usize {
        let mut queue = self.request_queue.lock();
        let count = queue.len();

        // Process all pending requests (simplified - just mark as complete)
        while let Some(mut request) = queue.pop_front() {
            request.completion_status = IoCompletionStatus::Success;
            let mut completed = self.completed_requests.lock();
            *completed += 1;
        }

        count
    }

    /// Get statistics
    pub fn get_stats(&self) -> (u64, u64) {
        let total = *self.total_requests.lock();
        let completed = *self.completed_requests.lock();
        (total, completed)
    }
}

/// Network packet types
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum PacketType {
    /// TCP packet
    Tcp,
    /// UDP packet
    Udp,
    /// ICMP packet
    Icmp,
    /// Raw packet
    Raw,
}

/// Network packet structure for processing
#[derive(Debug, Clone)]
pub struct NetworkPacket {
    /// Packet ID
    pub packet_id: u64,
    /// Packet size in bytes
    pub size: usize,
    /// Packet type
    pub packet_type: PacketType,
    /// Packet data (simplified - just size for now)
    pub data_len: usize,
    /// Packet data buffer
    pub data: [u8; 1536],
    /// Packet length
    pub length: usize,
    /// Timestamp
    pub timestamp: u64,
    /// Padding
    pub _padding: [u8; 0],
}

/// Network packet processor for optimized network I/O
pub struct NetworkProcessor {
    /// Queue of packets to process
    packet_queue: Mutex<VecDeque<NetworkPacket>>,
    /// Next packet ID
    next_packet_id: Mutex<u64>,
    /// Statistics
    total_packets: Mutex<u64>,
    processed_packets: Mutex<u64>,
    total_bytes: Mutex<u64>,
}

impl NetworkProcessor {
    /// Create a new network processor
    pub const fn new() -> Self {
        Self {
            packet_queue: Mutex::new(VecDeque::new()),
            next_packet_id: Mutex::new(1),
            total_packets: Mutex::new(0),
            processed_packets: Mutex::new(0),
            total_bytes: Mutex::new(0),
        }
    }

    /// Queue a packet for processing
    pub fn queue_packet(&self, mut packet: NetworkPacket) -> u64 {
        let mut next_id = self.next_packet_id.lock();
        packet.packet_id = *next_id;
        *next_id += 1;
        drop(next_id);

        let mut queue = self.packet_queue.lock();
        queue.push_back(packet.clone());
        drop(queue);

        let mut total = self.total_packets.lock();
        *total += 1;
        let mut bytes = self.total_bytes.lock();
        *bytes += packet.size as u64;

        packet.packet_id
    }

    /// Process queued packets
    pub fn process_packets(&self) -> usize {
        let mut queue = self.packet_queue.lock();
        let count = queue.len();

        // Process all queued packets (simplified - just dequeue)
        while let Some(_packet) = queue.pop_front() {
            let mut processed = self.processed_packets.lock();
            *processed += 1;
        }

        count
    }

    /// Get statistics
    pub fn get_stats(&self) -> (u64, u64, u64) {
        let total = *self.total_packets.lock();
        let processed = *self.processed_packets.lock();
        let bytes = *self.total_bytes.lock();
        (total, processed, bytes)
    }
}

lazy_static! {
    /// Global I/O scheduler instance
    static ref IO_SCHEDULER: IoScheduler = IoScheduler::new();

    /// Global network processor instance
    static ref NETWORK_PROCESSOR: NetworkProcessor = NetworkProcessor::new();
}

/// Initialize the I/O optimization system
pub fn init_io_system() -> Result<(), &'static str> {
    // I/O system is initialized via lazy_static
    // Additional setup can be added here if needed
    Ok(())
}

/// Get the global I/O scheduler
pub fn io_scheduler() -> &'static IoScheduler {
    &IO_SCHEDULER
}

/// Get the global network processor
pub fn network_processor() -> &'static NetworkProcessor {
    &NETWORK_PROCESSOR
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_io_scheduler_creation() {
        let scheduler = IoScheduler::new();
        let (total, completed) = scheduler.get_stats();
        assert_eq!(total, 0);
        assert_eq!(completed, 0);
    }

    #[test]
    fn test_io_request_submission() {
        let scheduler = IoScheduler::new();
        let request = IoRequest {
            request_id: 0,
            request_type: IoRequestType::Read,
            priority: IoPriority::Normal,
            target: 0,
            offset: 0,
            completion_status: IoCompletionStatus::Pending,
        };

        let id = scheduler.submit_request(request);
        assert_eq!(id, 1);

        let (total, _) = scheduler.get_stats();
        assert_eq!(total, 1);
    }

    #[test]
    fn test_network_processor_creation() {
        let processor = NetworkProcessor::new();
        let (total, processed, bytes) = processor.get_stats();
        assert_eq!(total, 0);
        assert_eq!(processed, 0);
        assert_eq!(bytes, 0);
    }
}

// =============================================================================
// I/O Statistics and Optimization Functions
// =============================================================================

/// I/O statistics structure containing aggregated metrics
#[derive(Debug, Clone, Copy, Default)]
pub struct IoStatistics {
    /// Total number of I/O requests submitted
    pub total_requests: u64,
    /// Number of completed requests
    pub completed_requests: u64,
    /// Number of pending requests
    pub pending_requests: u64,
    /// Total network packets processed
    pub total_packets: u64,
    /// Processed network packets
    pub processed_packets: u64,
    /// Total bytes transferred via network
    pub total_network_bytes: u64,
    /// Average queue depth
    pub avg_queue_depth: u64,
    /// Peak queue depth
    pub peak_queue_depth: u64,
}

/// Collects and returns aggregated I/O statistics across all schedulers.
///
/// This function gathers metrics from both the I/O scheduler and network
/// processor to provide a comprehensive view of system I/O performance.
///
/// # Returns
///
/// An `IoStatistics` structure containing current I/O metrics.
///
/// # Example
///
/// ```
/// let stats = get_io_statistics();
/// if stats.pending_requests > 100 {
///     // Consider throttling new requests
/// }
/// ```
pub fn get_io_statistics() -> IoStatistics {
    let (io_total, io_completed) = IO_SCHEDULER.get_stats();
    let (net_total, net_processed, net_bytes) = NETWORK_PROCESSOR.get_stats();

    let pending = io_total.saturating_sub(io_completed);

    IoStatistics {
        total_requests: io_total,
        completed_requests: io_completed,
        pending_requests: pending,
        total_packets: net_total,
        processed_packets: net_processed,
        total_network_bytes: net_bytes,
        avg_queue_depth: if io_total > 0 { pending } else { 0 },
        peak_queue_depth: pending, // In production, track historical peak
    }
}

/// Flushes all pending I/O requests, ensuring data integrity.
///
/// This function processes all queued I/O requests and network packets,
/// blocking until completion. Use this before system shutdown or when
/// data consistency is critical.
///
/// # Returns
///
/// A tuple containing (io_requests_flushed, network_packets_flushed).
pub fn flush_all_io() -> (usize, usize) {
    let io_flushed = IO_SCHEDULER.process_requests();
    let net_flushed = NETWORK_PROCESSOR.process_packets();
    (io_flushed, net_flushed)
}

/// Optimizes I/O request ordering using elevator algorithm (SCAN).
///
/// Reorders pending requests to minimize seek time on rotational media.
/// For SSDs, this provides sequential access patterns which can still
/// improve performance through better cache utilization.
///
/// # Returns
///
/// The number of requests that were reordered.
pub fn optimize_request_order() -> usize {
    let mut queue = IO_SCHEDULER.request_queue.lock();
    let len = queue.len();

    if len <= 1 {
        return 0;
    }

    // Convert to Vec for sorting
    let mut requests: Vec<IoRequest> = queue.drain(..).collect();

    // Sort by offset (elevator algorithm - SCAN)
    requests.sort_by(|a, b| {
        // First by priority (higher priority first)
        match b.priority.cmp(&a.priority) {
            core::cmp::Ordering::Equal => {
                // Then by offset for locality
                a.offset.cmp(&b.offset)
            }
            other => other,
        }
    });

    // Put back into queue
    for request in requests {
        queue.push_back(request);
    }

    len
}

/// Batches multiple small I/O requests into larger operations.
///
/// This function examines pending requests and merges adjacent ones
/// when possible, reducing overhead and improving throughput.
///
/// # Arguments
///
/// * `max_batch_size` - Maximum size of a batched request in bytes
///
/// # Returns
///
/// The number of requests that were merged.
pub fn batch_io_requests(max_batch_size: usize) -> usize {
    let mut queue = IO_SCHEDULER.request_queue.lock();

    if queue.len() <= 1 {
        return 0;
    }

    let mut requests: Vec<IoRequest> = queue.drain(..).collect();
    let original_count = requests.len();

    // Sort by device and offset for merging opportunities
    requests.sort_by(|a, b| {
        match a.device_id.cmp(&b.device_id) {
            core::cmp::Ordering::Equal => a.offset.cmp(&b.offset),
            other => other,
        }
    });

    let mut merged: Vec<IoRequest> = Vec::new();
    let mut i = 0;

    while i < requests.len() {
        let mut current = requests[i].clone();

        // Try to merge with following requests
        while i + 1 < requests.len() {
            let next = &requests[i + 1];

            // Check if requests can be merged:
            // - Same device
            // - Same request type
            // - Adjacent offsets
            // - Combined size within limit
            let is_adjacent = current.offset + current.size as u64 == next.offset;
            let same_type = current.request_type == next.request_type;
            let same_device = current.device_id == next.device_id;
            let within_limit = current.size + next.size <= max_batch_size;

            if is_adjacent && same_type && same_device && within_limit {
                // Merge: extend current request
                current.size += next.size;
                i += 1;
            } else {
                break;
            }
        }

        merged.push(current);
        i += 1;
    }

    let merged_count = original_count - merged.len();

    // Put merged requests back
    for request in merged {
        queue.push_back(request);
    }

    merged_count
}

/// Sets the I/O priority for a specific request.
///
/// # Arguments
///
/// * `request_id` - The ID of the request to modify
/// * `priority` - The new priority level
///
/// # Returns
///
/// `true` if the request was found and updated, `false` otherwise.
pub fn set_request_priority(request_id: u64, priority: IoPriority) -> bool {
    let mut queue = IO_SCHEDULER.request_queue.lock();

    for request in queue.iter_mut() {
        if request.request_id == request_id {
            request.priority = priority;
            return true;
        }
    }

    false
}

/// Cancels a pending I/O request.
///
/// # Arguments
///
/// * `request_id` - The ID of the request to cancel
///
/// # Returns
///
/// `true` if the request was found and cancelled, `false` otherwise.
pub fn cancel_io_request(request_id: u64) -> bool {
    let mut queue = IO_SCHEDULER.request_queue.lock();

    if let Some(pos) = queue.iter().position(|r| r.request_id == request_id) {
        queue.remove(pos);
        return true;
    }

    false
}

/// Gets the current queue depth for the I/O scheduler.
///
/// # Returns
///
/// The number of pending I/O requests.
pub fn get_queue_depth() -> usize {
    IO_SCHEDULER.request_queue.lock().len()
}

/// Processes I/O requests up to a specified limit.
///
/// This function is useful for rate-limiting I/O processing to prevent
/// starvation of other system tasks.
///
/// # Arguments
///
/// * `max_requests` - Maximum number of requests to process
///
/// # Returns
///
/// The actual number of requests processed.
pub fn process_requests_limited(max_requests: usize) -> usize {
    let mut queue = IO_SCHEDULER.request_queue.lock();
    let mut completed = IO_SCHEDULER.completed_requests.lock();

    let to_process = core::cmp::min(queue.len(), max_requests);

    for _ in 0..to_process {
        if let Some(mut request) = queue.pop_front() {
            request.completion_status = IoCompletionStatus::Success;
            *completed += 1;
        }
    }

    to_process
}

/// Creates a new I/O request with default values.
///
/// # Arguments
///
/// * `request_type` - The type of I/O operation
/// * `device_id` - Target device identifier
/// * `offset` - Byte offset for the operation
/// * `size` - Size of the operation in bytes
///
/// # Returns
///
/// A new `IoRequest` with the specified parameters and default values.
pub fn create_io_request(
    request_type: IoRequestType,
    device_id: u32,
    offset: u64,
    size: usize,
) -> IoRequest {
    IoRequest {
        request_id: 0, // Will be assigned on submission
        id: 0,
        request_type,
        priority: IoPriority::Normal,
        target: device_id,
        offset,
        buffer: None,
        size,
        device_id,
        waker: None,
        completion_status: IoCompletionStatus::Pending,
    }
}

/// Creates a new network packet with default values.
///
/// # Arguments
///
/// * `packet_type` - The type of network packet
/// * `data` - Packet data slice (up to 1536 bytes)
///
/// # Returns
///
/// A new `NetworkPacket` with the specified parameters.
pub fn create_network_packet(packet_type: PacketType, data: &[u8]) -> NetworkPacket {
    let mut packet_data = [0u8; 1536];
    let len = core::cmp::min(data.len(), 1536);
    packet_data[..len].copy_from_slice(&data[..len]);

    NetworkPacket {
        packet_id: 0, // Will be assigned on queuing
        size: len,
        packet_type,
        data_len: len,
        data: packet_data,
        length: len,
        timestamp: 0, // Should be set by caller with actual timestamp
        _padding: [],
    }
}

/// Submits an I/O request to the global scheduler.
///
/// Convenience function that wraps `IoScheduler::submit_request`.
///
/// # Arguments
///
/// * `request` - The I/O request to submit
///
/// # Returns
///
/// The assigned request ID.
pub fn submit_io_request(request: IoRequest) -> u64 {
    IO_SCHEDULER.submit_request(request)
}

/// Queues a network packet for processing.
///
/// Convenience function that wraps `NetworkProcessor::queue_packet`.
///
/// # Arguments
///
/// * `packet` - The network packet to queue
///
/// # Returns
///
/// The assigned packet ID.
pub fn queue_network_packet(packet: NetworkPacket) -> u64 {
    NETWORK_PROCESSOR.queue_packet(packet)
}

/// Checks if the I/O system is idle (no pending requests).
///
/// # Returns
///
/// `true` if there are no pending I/O requests or network packets.
pub fn is_io_idle() -> bool {
    let io_empty = IO_SCHEDULER.request_queue.lock().is_empty();
    let net_empty = NETWORK_PROCESSOR.packet_queue.lock().is_empty();
    io_empty && net_empty
}

/// Waits for all I/O to complete by processing all pending requests.
///
/// This is a blocking operation that processes all queued I/O.
///
/// # Returns
///
/// Total number of operations completed.
pub fn wait_for_io_completion() -> usize {
    let mut total = 0;

    // Process until queues are empty
    loop {
        let io_processed = IO_SCHEDULER.process_requests();
        let net_processed = NETWORK_PROCESSOR.process_packets();

        if io_processed == 0 && net_processed == 0 {
            break;
        }

        total += io_processed + net_processed;
    }

    total
}
